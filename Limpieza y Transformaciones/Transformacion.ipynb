{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_common_player_info = pd.read_csv('common_player_info.csv')\n",
    "comp_player = pd.read_csv('player.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraccion de datos\n",
    "tables = [\"common_player_info\", \"draft_combine_stats\", \"draft_history\", \"game_info\", \"game\", \"inactive_players\",\n",
    "          \"line_score\", \"other_stats\", \"play_by_play\", \"player\", \"team_details\", \"team\"]\n",
    "\n",
    "# Cargar cada archivo CSV en un DataFrame con el nombre del elemento en `tables`\n",
    "for table_name in tables:\n",
    "    globals()[table_name] = pd.read_csv(f\"{table_name}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el archivo de texto y escribir la información de las tablas\n",
    "with open(\"info_tablas.txt\", \"w\") as file:\n",
    "    file.write(\"TABLES: (registros/columnas)\\n\")\n",
    "    \n",
    "    # Recorrer la lista `tables` para agregar la información de cada DataFrame\n",
    "    for i, table_name in enumerate(tables, start=1):\n",
    "        df = globals()[table_name]  # Obtener el DataFrame correspondiente\n",
    "        shape_info = f'{df.shape[0]}/{df.shape[1]}'  # Formato de (registros/columnas)\n",
    "        \n",
    "        # Escribir la información de la tabla\n",
    "        file.write(f'      \"{i}\") \"{table_name}\": {shape_info}\\n')\n",
    "        file.write(\"           COLUMNAS: (formato)\\n\")\n",
    "        \n",
    "        # Recorrer cada columna para obtener el primer valor no nulo o \"Sin datos disponibles\"\n",
    "        first_non_null_values = []\n",
    "        for column in df.columns:\n",
    "            # Obtener el primer valor no nulo de la columna o \"Sin datos disponibles\"\n",
    "            first_non_null = df[column].dropna().iloc[0] if not df[column].dropna().empty else \"Sin datos disponibles\"\n",
    "            first_non_null_values.append(first_non_null)\n",
    "        \n",
    "        # Escribir las columnas y los primeros valores no nulos\n",
    "        file.write(f'           {list(df.columns)}: {first_non_null_values}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario vacío\n",
    "column_dict = {}\n",
    "\n",
    "# Recorrer cada nombre en la lista \"tables\"\n",
    "for table_name in tables:\n",
    "    # Obtener el DataFrame usando globals()\n",
    "    df = globals()[table_name]\n",
    "    \n",
    "    # Recorrer las columnas del DataFrame\n",
    "    for column in df.columns:\n",
    "        # Si la columna no está en el diccionario, inicializa una lista\n",
    "        if column not in column_dict:\n",
    "            column_dict[column] = []\n",
    "        \n",
    "        # Agregar el nombre del DataFrame a la lista\n",
    "        column_dict[column].append(table_name)\n",
    "\n",
    "# Nombre del archivo donde se guardará la información\n",
    "output_file = 'columnas_y_dataframes.txt'\n",
    "\n",
    "# Abrir el archivo en modo escritura\n",
    "with open(output_file, 'w') as file:\n",
    "    # Recorrer el diccionario\n",
    "    for column, dataframes in column_dict.items():\n",
    "        # Escribir el índice y sus valores en el archivo\n",
    "        file.write(f\"{column}: {', '.join(dataframes)}\\n\")\n",
    "\n",
    "print(f\"Los datos se han guardado en {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar por año\n",
    "for table_name in tables:\n",
    "    if 'season' in globals()[table_name].columns:\n",
    "        globals()[table_name] = globals()[table_name][globals()[table_name]['season'] > 1999]\n",
    "    elif 'game_date' in globals()[table_name].columns:\n",
    "        globals()[table_name]['game_date'] = pd.to_datetime(globals()[table_name]['game_date'])\n",
    "        globals()[table_name] = globals()[table_name][globals()[table_name]['game_date'].dt.year > 1999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar columnas para evitar ambiguedades y para igualar nombres de columnas que tienen los mismos atributos\n",
    "rename_columns = {\n",
    "    'common_player_info': {\n",
    "        'person_id': 'player_id',\n",
    "        'display_first_last': 'player_name',\n",
    "        'draft_round': 'round_pick'\n",
    "    },\n",
    "    'draft_history': {\n",
    "        'person_id': 'player_id'\n",
    "    },\n",
    "    'team': {\n",
    "        'id': 'team_id',\n",
    "        'full_name': 'team_name'\n",
    "    },\n",
    "    'player': {\n",
    "        'id': 'player_id',\n",
    "        'full_name': 'player_name'\n",
    "    },\n",
    "    'inactive_players': {\n",
    "        'jersey_num': 'jersey'\n",
    "    },\n",
    "    'line_score': {\n",
    "        'game_date_est': 'game_date'\n",
    "    },\n",
    "    'team_details': {\n",
    "        'abbreviation': 'team_abbreviation',\n",
    "        'nickname': 'team_nickname',\n",
    "        'city': 'team_city',\n",
    "        'yearfounded': 'year_founded'\n",
    "    },\n",
    "    'team_details': {\n",
    "        'abbreviation': 'team_abbreviation',\n",
    "        'nickname': 'team_nickname',\n",
    "        'city': 'team_city',\n",
    "        'state': 'team_state'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Apply renaming for each DataFrame\n",
    "for df_name, renames in rename_columns.items():\n",
    "    globals()[df_name].rename(columns=renames, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los datos del resto de los df por los df ya filtrados\n",
    "# Create the list of unique game_id values from the game DataFrame\n",
    "unique_game_ids = game['game_id'].unique().tolist()\n",
    "unique_player_ids = draft_combine_stats['player_id'].unique().tolist()\n",
    "unique_team_ids = draft_history['team_id'].unique().tolist()\n",
    "\n",
    "\n",
    "# Loop through each DataFrame name in the tables list, filtering based on game_id if the column exists\n",
    "for table_name in tables:\n",
    "    df = globals()[table_name]\n",
    "    if 'player_id' in df.columns:\n",
    "        globals()[table_name] = df[df['player_id'].isin(unique_player_ids)]\n",
    "        \n",
    "for table_name in tables:\n",
    "    df = globals()[table_name]\n",
    "    if 'team_id' in df.columns:\n",
    "        globals()[table_name] = df[df['team_id'].isin(unique_team_ids)]\n",
    "\n",
    "for table_name in tables:\n",
    "    df = globals()[table_name]\n",
    "    if 'game_id' in df.columns:\n",
    "        globals()[table_name] = df[df['game_id'].isin(unique_game_ids)]\n",
    "\n",
    "\n",
    "# Filter play_by_play DataFrame\n",
    "play_by_play = play_by_play[\n",
    "    play_by_play['player1_id'].isin(unique_player_ids) |\n",
    "    play_by_play['player2_id'].isin(unique_player_ids) |\n",
    "    play_by_play['player3_id'].isin(unique_player_ids)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     player_id          player_name  birthdate             school  \\\n",
      "0       203919         Jordan Adams 1994-07-08               UCLA   \n",
      "1       203500         Steven Adams 1993-07-20         Pittsburgh   \n",
      "2      1628959         Rawle Alkins 1997-10-29            Arizona   \n",
      "3      1628959         Rawle Alkins 1997-10-29            Arizona   \n",
      "4      1628959         Rawle Alkins 1997-10-29            Arizona   \n",
      "..         ...                  ...        ...                ...   \n",
      "108    1628414  Sindarius Thornwell 1994-11-15     South Carolina   \n",
      "109    1628401        Derrick White 1994-07-02           Colorado   \n",
      "110     203912          C.J. Wilcox 1990-12-30         Washington   \n",
      "111    1626210        Alan Williams 1993-01-28  Cal-Santa Barbara   \n",
      "112    1629684       Grant Williams 1998-11-30          Tennessee   \n",
      "\n",
      "         country              last_affiliation  height      weight season_exp  \\\n",
      "0            USA                      UCLA/USA   75.50  209.00 lbs          3   \n",
      "1    New Zealand        Pittsburgh/New Zealand   82.75  265.00 lbs         10   \n",
      "2            USA                   Arizona/USA   74.50  225.00 lbs          2   \n",
      "3            USA                   Arizona/USA   74.75  225.00 lbs          2   \n",
      "4            USA                   Arizona/USA   74.50  225.00 lbs          2   \n",
      "..           ...                           ...     ...         ...        ...   \n",
      "108          USA            South Carolina/USA   75.50  215.00 lbs          5   \n",
      "109          USA                  Colorado/USA   75.25  190.00 lbs          6   \n",
      "110          USA                Washington/USA   75.50  195.00 lbs          4   \n",
      "111          USA  California-Santa Barbara/USA   79.25  265.00 lbs          5   \n",
      "112          USA                 Tennessee/USA   77.75  236.00 lbs          4   \n",
      "\n",
      "    jersey  ...           playercode from_year to_year dleague_flag nba_flag  \\\n",
      "0        3  ...         jordan_adams      2014    2015            Y        Y   \n",
      "1        4  ...         steven_adams      2013    2023            N        Y   \n",
      "2       20  ...         rawle_alkins      2018    2018            Y        Y   \n",
      "3       20  ...         rawle_alkins      2018    2018            Y        Y   \n",
      "4       20  ...         rawle_alkins      2018    2018            Y        Y   \n",
      "..     ...  ...                  ...       ...     ...          ...      ...   \n",
      "108     15  ...  sindarius_thornwell      2017    2020            Y        Y   \n",
      "109      9  ...        derrick_white      2017    2023            Y        Y   \n",
      "110     23  ...            cj_wilcox      2014    2017            Y        Y   \n",
      "111     15  ...        alan_williams      2015    2018            Y        Y   \n",
      "112     12  ...       grant_williams      2019    2023            N        Y   \n",
      "\n",
      "    games_played_flag draft_year round_pick draft_number greatest_75_flag  \n",
      "0                   Y       2014          1           22                N  \n",
      "1                   Y       2013          1           12                N  \n",
      "2                   Y  Undrafted  Undrafted    Undrafted                N  \n",
      "3                   Y  Undrafted  Undrafted    Undrafted                N  \n",
      "4                   Y  Undrafted  Undrafted    Undrafted                N  \n",
      "..                ...        ...        ...          ...              ...  \n",
      "108                 Y       2017          2           48                N  \n",
      "109                 Y       2017          1           29                N  \n",
      "110                 Y       2014          1           28                N  \n",
      "111                 Y  Undrafted  Undrafted    Undrafted                N  \n",
      "112                 Y       2019          1           22                N  \n",
      "\n",
      "[113 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Asegúrate de que 'player_id' en ambos DataFrames esté en el mismo formato, por ejemplo, tipo int\n",
    "common_player_info['player_id'] = common_player_info['player_id'].astype(int)\n",
    "draft_combine_stats['player_id'] = draft_combine_stats['player_id'].astype(int)\n",
    "\n",
    "# Realizar el merge entre common_player_info y draft_combine_stats basado en player_id\n",
    "merged_df = common_player_info.merge(\n",
    "    draft_combine_stats[['player_id', 'height_wo_shoes']],\n",
    "    on='player_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Reemplazar directamente los valores de 'height' con 'height_wo_shoes'\n",
    "merged_df['height'] = merged_df['height_wo_shoes']\n",
    "\n",
    "# Eliminar la columna 'height_wo_shoes' ya que solo se usaba para llenar valores en 'height'\n",
    "merged_df = merged_df.drop(columns=['height_wo_shoes'])\n",
    "\n",
    "# Actualizar common_player_info con los registros actualizados\n",
    "common_player_info = merged_df\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(common_player_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'height_w_shoes_ft_in' removed from draft_combine_stats\n",
      "Column 'height_wo_shoes_ft_in' removed from draft_combine_stats\n",
      "Column 'wingspan_ft_in' removed from draft_combine_stats\n",
      "Column 'standing_reach_ft_in' removed from draft_combine_stats\n"
     ]
    }
   ],
   "source": [
    "# Eliminar Columnas que no se vayan a usar\n",
    "# List of DataFrame names and columns to drop\n",
    "columns_to_drop = {\n",
    "    'first_name': ['common_player_info', 'draft_combine_stats', 'inactive_players', 'player'],\n",
    "    'last_name': ['common_player_info', 'draft_combine_stats', 'inactive_players', 'player'],\n",
    "    'display_fi_last': ['common_player_info'],\n",
    "    'display_last_comma_first': ['common_player_info'],\n",
    "    'player_slug': ['common_player_info'],\n",
    "    'facebook': ['team_details'],\n",
    "    'instagram': ['team_details'],\n",
    "    'twitter': ['team_details'],\n",
    "    'neutraldescription': ['play_by_play'],\n",
    "    'height_w_shoes_ft_in': ['draft_combine_stats'],\n",
    "    'height_wo_shoes_ft_in': ['draft_combine_stats'],\n",
    "    'wingspan_ft_in': ['draft_combine_stats'],\n",
    "    'standing_reach_ft_in': ['draft_combine_stats']\n",
    "}\n",
    "\n",
    "# Loop through each column and its associated DataFrames\n",
    "for column, dfs in columns_to_drop.items():\n",
    "    for df_name in dfs:\n",
    "        df = globals()[df_name]  # Access the DataFrame by name\n",
    "        if column in df.columns:  # Check if the column exists\n",
    "            df.drop(columns=[column], inplace=True)  # Drop the column\n",
    "            print(f\"Column '{column}' removed from {df_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar columnas para el formateo\n",
    "columnas_string = ['player_id', 'player_name', 'school', 'country', 'last_affiliation', 'jersey', 'position', \n",
    "'team_id', 'team_name', 'team_abbreviation', 'team_code', 'team_city', 'playercode',\n",
    "'position', 'draft_type', 'organization', 'organization_type', 'game_id', 'team_id_home',\n",
    "'team_abbreviation_home', 'team_name_home', 'matchup_home', 'team_id_away',\n",
    "'team_abbreviation_away', 'team_name_away', 'matchup_away', 'season_type', 'team_city_name_home',\n",
    "'team_nickname_home', 'team_city_name_away', 'team_nickname_away', 'league_id', 'eventnum',\n",
    "'eventmsgtype', 'eventmsgactiontype', 'homedescription', 'visitordescription', 'score',\n",
    "'person1type', 'player1_id', 'player1_name', 'player1_team_id', 'player1_team_city', \n",
    "'player1_team_nickname', 'player1_team_abbreviation', 'player2_id', 'player2_name',\n",
    "'player2_team_id', 'player2_team_city', 'player2_team_nickname', 'player2_team_abbreviation',\n",
    "'player3_id', 'player3_name', 'player3_team_id', 'player3_team_city', 'player3_team_nickname',\n",
    "'player3_team_abbreviation', 'owner', 'generalmanager', 'headcoach', 'dleagueaffiliation', 'team_state',\n",
    "'season_exp', 'from_year', 'to_year', 'draft_year', 'round_pick', 'draft_number', 'season', 'round_number',\n",
    "'overall_pick', 'season_id', 'arena']\n",
    "columnas_bool = ['rosterstatus', 'games_played_current_season_flag', 'dleague_flag', 'nba_flag',\n",
    "'games_played_flag', 'greatest_75_flag', 'player_profile_flag', 'wl_home', 'video_available_home',\n",
    "'wl_away', 'video_available_away', 'video_available_flag', 'is_active']\n",
    "columnas_date = ['birthdate', 'game_date']\n",
    "columnas_timestring = ['game_time', 'wctimestring', 'pctimestring']\n",
    "columnas_pulgadas = ['height', 'height_wo_shoes', 'height_w_shoes', 'wingspan', 'standing_reach', 'hand_length',\n",
    "'hand_width', 'standing_vertical_leap', 'max_vertical_leap']\n",
    "columnas_libras = ['weight']\n",
    "columnas_float3 = ['body_fat_pct', 'fg_pct_home', 'fg3_pct_home', 'ft_pct_home', 'fg_pct_away', 'fg3_pct_away', 'ft_pct_away']\n",
    "columnas_tiempo = ['lane_agility_time', 'modified_lane_agility_time', 'three_quarter_sprint']\n",
    "columnas_int = ['bench_press', 'attendance', 'fgm_home',\n",
    "'fga_home', 'fg3m_home', 'fg3a_home', 'ftm_home', 'fta_home', 'oreb_home', 'dreb_home',\n",
    "'reb_home', 'ast_home', 'stl_home', 'blk_home', 'tov_home', 'pts_home', 'plus_minus_home',\n",
    "'fgm_away', 'fga_away', 'fg3m_away', 'fg3a_away', 'ftm_away', 'fta_away', 'oreb_away',\n",
    "'dreb_away', 'reb_away', 'ast_away', 'stl_away', 'blk_away', 'tov_away', 'pf_away', 'pts_away',\n",
    "'plus_minus_away', 'game_sequence', 'pts_qtr1_home', 'pts_qtr2_home', 'pts_qtr3_home',\n",
    "'pts_qtr4_home', 'pts_ot1_home', 'pts_ot2_home', 'pts_ot3_home', 'pts_ot4_home', 'pts_ot5_home',\n",
    "'pts_ot6_home', 'pts_ot7_home', 'pts_ot8_home', 'pts_ot9_home', 'pts_ot10_home', 'pts_home',\n",
    "'pts_qtr1_away', 'pts_qtr2_away', 'pts_qtr3_away', 'pts_qtr4_away', 'pts_ot1_away',\n",
    "'pts_ot2_away', 'pts_ot3_away', 'pts_ot4_away', 'pts_ot5_away', 'pts_ot6_away', 'pts_ot7_away',\n",
    "'pts_ot8_away', 'pts_ot9_away', 'pts_ot10_away', 'pts_away', 'pts_paint_home', 'pts_2nd_chance_home',\n",
    "'pts_fb_home', 'largest_lead_home', 'lead_changes', 'times_tied', 'team_turnovers_home',\n",
    "'total_turnovers_home', 'team_rebounds_home', 'pts_off_to_home', 'pts_paint_away',\n",
    "'pts_2nd_chance_away', 'pts_fb_away', 'largest_lead_away', 'team_turnovers_away',\n",
    "'total_turnovers_away', 'team_rebounds_away', 'pts_off_to_away', 'period', 'scoremargin',\n",
    "'yearfounded', 'arenacapacity']\n",
    "columnas_fracciones = ['spot_fifteen_corner_left', 'spot_fifteen_break_left', 'spot_fifteen_top_key',\n",
    "'spot_fifteen_break_right', 'spot_fifteen_corner_right', 'spot_college_corner_left',\n",
    "'spot_college_break_left', 'spot_college_top_key', 'spot_college_break_right',\n",
    "'spot_college_corner_right', 'spot_nba_corner_left', 'spot_nba_break_left',\n",
    "'spot_nba_top_key', 'spot_nba_break_right', 'spot_nba_corner_right',\n",
    "'off_drib_fifteen_break_left', 'off_drib_fifteen_top_key', 'off_drib_fifteen_break_right',\n",
    "'off_drib_college_break_left', 'off_drib_college_top_key', 'off_drib_college_break_right',\n",
    "'on_move_fifteen', 'on_move_college']\n",
    "columnas_ratios = ['team_wins_losses_home', 'team_wins_losses_away']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar columnas de fracciones a su formato correcto\n",
    "dataframes = [draft_combine_stats, line_score]  # your target dataframes\n",
    "\n",
    "# Define the conversion function\n",
    "def to_fraction(value):\n",
    "    if isinstance(value, str) and '-' in value:\n",
    "        parts = value.split('-')\n",
    "        if len(parts) == 2 and parts[0].isdigit() and parts[1].isdigit():\n",
    "            x, y = parts\n",
    "            return Fraction(int(x), int(y))\n",
    "    # Return original value if not in 'x-y' format or if malformed\n",
    "    return value\n",
    "\n",
    "# Apply the transformation to each specified column in each dataframe\n",
    "for df in dataframes:\n",
    "    for col in columnas_fracciones:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(to_fraction)\n",
    "\n",
    "# Now 'x-y' formatted strings in specified columns are converted to Fraction objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame shape: (233, 41)\n"
     ]
    }
   ],
   "source": [
    "# Filtrar draft_combine_stats para obtener solo los registros que tengan informacion acerca de las pruebas de tiro en alguna de las ligas\n",
    "# Create a mask for rows with at least 5 non-null values in 'columnas_fracciones'\n",
    "mask = draft_combine_stats[columnas_fracciones].notna().sum(axis=1) >= 5\n",
    "\n",
    "# Apply the mask to filter out rows that don't meet the condition\n",
    "draft_combine_stats = draft_combine_stats[mask].copy()\n",
    "\n",
    "print(\"Filtered DataFrame shape:\", draft_combine_stats.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar valores nulos de common_player_info, draft_combine_stats, game_info, inactive_players, line_score, other_stats\n",
    "# Merge the DataFrames on player_id\n",
    "common_player_info.fillna(0, inplace=True)\n",
    "draft_combine_stats.fillna(0, inplace=True)\n",
    "game_info.fillna(0, inplace=True)\n",
    "inactive_players.fillna(0, inplace=True)\n",
    "line_score.fillna(0, inplace=True)\n",
    "other_stats.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar valores nulos en game (wl_home, ft_pct_home, wl_away, ft_pct_away)\n",
    "# Aquí definimos la lógica para rellenar wl_home y wl_away\n",
    "def set_wl(row):\n",
    "    if row['pts_home'] > row['pts_away']:\n",
    "        return pd.Series(['W', 'L'])  # wl_home, wl_away\n",
    "    else:\n",
    "        return pd.Series(['L', 'W'])  # wl_home, wl_away\n",
    "\n",
    "# Aplicamos la función y rellenamos las columnas correspondientes\n",
    "game[['wl_home', 'wl_away']] = game.apply(set_wl, axis=1)\n",
    "\n",
    "\n",
    "def calculate_pct(row):\n",
    "    row['fg_pct_home'] = row['fgm_home'] / row['fga_home'] if row['fga_home'] != 0 else 0\n",
    "    row['fg_pct_away'] = row['fgm_away'] / row['fga_away'] if row['fga_away'] != 0 else 0\n",
    "    row['fg3_pct_home'] = row['fg3m_home'] / row['fg3a_home'] if row['fg3a_home'] != 0 else 0\n",
    "    row['fg3_pct_away'] = row['fg3m_away'] / row['fg3a_away'] if row['fg3a_away'] != 0 else 0\n",
    "    row['ft_pct_home'] = row['ftm_home'] / row['fta_home'] if row['fta_home'] != 0 else 0\n",
    "    row['ft_pct_away'] = row['ftm_away'] / row['fta_away'] if row['fta_away'] != 0 else 0\n",
    "    return row\n",
    "\n",
    "# Aplicamos la función a cada fila\n",
    "game = game.apply(calculate_pct, axis=1)\n",
    "\n",
    "# Verificamos el resultado\n",
    "game.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar valores nulos en play_byplay\n",
    "\n",
    "# Realizamos un merge de 'play_by_play' con 'draft_history' usando 'player3_id' y 'player_id'\n",
    "merged_df = play_by_play.merge(\n",
    "    comp_player[['id', 'full_name']],\n",
    "    how='left',\n",
    "    left_on='player1_id',\n",
    "    right_on='id'\n",
    ")\n",
    "\n",
    "# Rellenamos los valores nulos de las columnas de 'play_by_play' con los valores correspondientes de 'draft_history'\n",
    "merged_df['player1_name'] = merged_df['player1_name'].combine_first(merged_df['full_name'])\n",
    "\n",
    "# Eliminamos las columnas adicionales para regresar al formato original\n",
    "play_by_play = merged_df[play_by_play.columns]\n",
    "\n",
    "# Realizamos un merge de 'play_by_play' con 'draft_history' usando 'player3_id' y 'player_id'\n",
    "merged_df = play_by_play.merge(\n",
    "    comp_common_player_info[['person_id', 'display_first_last', 'team_code', 'team_id', 'team_city', 'team_abbreviation']],\n",
    "    how='left',\n",
    "    left_on='player3_id',\n",
    "    right_on='person_id'\n",
    ")\n",
    "\n",
    "# Rellenamos los valores nulos de las columnas de 'play_by_play' con los valores correspondientes de 'draft_history'\n",
    "merged_df['player3_name'] = merged_df['player3_name'].combine_first(merged_df['display_first_last'])\n",
    "merged_df['player3_team_nickname'] = merged_df['player3_team_nickname'].combine_first(merged_df['team_code'])\n",
    "merged_df['player3_team_id'] = merged_df['player3_team_id'].combine_first(merged_df['team_id'])\n",
    "merged_df['player3_team_city'] = merged_df['player3_team_city'].combine_first(merged_df['team_city'])\n",
    "merged_df['player3_team_abbreviation'] = merged_df['player3_team_abbreviation'].combine_first(merged_df['team_abbreviation'])\n",
    "\n",
    "# Eliminamos las columnas adicionales para regresar al formato original\n",
    "play_by_play = merged_df[play_by_play.columns]\n",
    "\n",
    "# Realizamos un merge de 'play_by_play' con 'draft_history' usando 'player2_id' y 'player_id'\n",
    "merged_df = play_by_play.merge(\n",
    "    comp_common_player_info[['person_id', 'display_first_last', 'team_code', 'team_id', 'team_city', 'team_abbreviation']],\n",
    "    how='left',\n",
    "    left_on='player2_id',\n",
    "    right_on='person_id'\n",
    ")\n",
    "\n",
    "# Rellenamos los valores nulos de las columnas de 'play_by_play' con los valores correspondientes de 'draft_history'\n",
    "merged_df['player2_name'] = merged_df['player2_name'].combine_first(merged_df['display_first_last'])\n",
    "merged_df['player2_team_nickname'] = merged_df['player2_team_nickname'].combine_first(merged_df['team_code'])\n",
    "merged_df['player2_team_id'] = merged_df['player2_team_id'].combine_first(merged_df['team_id'])\n",
    "merged_df['player2_team_city'] = merged_df['player2_team_city'].combine_first(merged_df['team_city'])\n",
    "merged_df['player2_team_abbreviation'] = merged_df['player2_team_abbreviation'].combine_first(merged_df['team_abbreviation'])\n",
    "\n",
    "# Eliminamos las columnas adicionales para regresar al formato original\n",
    "play_by_play = merged_df[play_by_play.columns]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar resto de valores nulos con N/A ya que son strings entonces permiten ser rellenados de esa forma\n",
    "for table_name in tables:\n",
    "    globals()[table_name].fillna('N/A', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorremos cada DataFrame en la lista 'tables'\n",
    "for df in tables:\n",
    "    # Reemplazamos 'N/A' por 0 en las columnas que están en 'columnas_int'\n",
    "    for column in columnas_int:\n",
    "        if column in globals()[df].columns:\n",
    "            globals()[df][column] = globals()[df][column].replace('N/A', 0)\n",
    "            globals()[df][column] = globals()[df][column].replace('TIE', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicacion de formatos correspondientes\n",
    "# Recorrer cada DataFrame en la lista tables\n",
    "for df in tables:\n",
    "    \n",
    "    # Convertir columnas a string\n",
    "    for col in globals()[df].columns.intersection(columnas_string + columnas_bool + columnas_timestring):\n",
    "        globals()[df][col] = globals()[df][col].astype(str)\n",
    "    \n",
    "    # Convertir columnas a datetime\n",
    "    for col in globals()[df].columns.intersection(columnas_date):\n",
    "        globals()[df][col] = pd.to_datetime(globals()[df][col])  # 'coerce' convierte valores inválidos a NaT\n",
    "    \n",
    "    # Aplicar formato para columnas en pulgadas\n",
    "    for col in globals()[df].columns.intersection(columnas_pulgadas):\n",
    "        globals()[df][col] = globals()[df][col].astype(float).map(lambda x: f\"{x:.2f} in\")\n",
    "    \n",
    "    # Aplicar formato para columnas en libras\n",
    "    for col in globals()[df].columns.intersection(columnas_libras):\n",
    "        globals()[df][col] = globals()[df][col].astype(float).map(lambda x: f\"{x:.2f} lbs\")\n",
    "    \n",
    "    # Aplicar formato para columnas float con 3 decimales\n",
    "    for col in globals()[df].columns.intersection(columnas_float3):\n",
    "        globals()[df][col] = globals()[df][col].astype(float).round(3)\n",
    "    \n",
    "    '''# Aplicar formato para columnas de tiempo en segundos\n",
    "    for col in globals()[df].columns.intersection(columnas_tiempo):\n",
    "        globals()[df][col] = globals()[df][col].astype(float).map(lambda x: f\"{x:.3f} segs\")'''\n",
    "    \n",
    "    # Convertir columnas a enteros\n",
    "    for col in globals()[df].columns.intersection(columnas_int):\n",
    "        globals()[df][col] = globals()[df][col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your conversion functions\n",
    "def convert_inches(value):\n",
    "    if isinstance(value, str):\n",
    "        return round(float(value.replace('in', '').strip()), 2)\n",
    "    return round(value, 2) if value is not None else None\n",
    "\n",
    "def convert_pounds(value):\n",
    "    if isinstance(value, str):\n",
    "        return round(float(value.replace('lbs', '').strip()), 2)\n",
    "    return round(value, 2) if value is not None else None\n",
    "\n",
    "def convert_time(value):\n",
    "    if isinstance(value, str):\n",
    "        return round(float(value.replace('segs', '').strip()), 3)\n",
    "    return round(value, 3) if value is not None else None\n",
    "\n",
    "\n",
    "# Apply the conversions to each DataFrame\n",
    "for df in tables:\n",
    "    for col in columnas_pulgadas:\n",
    "        if col in globals()[df].columns:\n",
    "            globals()[df][col] = globals()[df][col].apply(convert_inches)\n",
    "\n",
    "    for col in columnas_libras:\n",
    "        if col in globals()[df].columns:\n",
    "            globals()[df][col] = globals()[df][col].apply(convert_pounds)\n",
    "\n",
    "    for col in columnas_tiempo:\n",
    "        if col in globals()[df].columns:\n",
    "            globals()[df][col] = globals()[df][col].apply(convert_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single ExcelWriter instance\n",
    "file_path = 'NBA_Filtrado2.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "    # Write each DataFrame to a separate sheet\n",
    "    common_player_info.to_excel(writer, index=False, sheet_name='common_player_info')\n",
    "    print('1')\n",
    "\n",
    "# Now using a new 'with' block but still writing to the same file\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a') as writer:\n",
    "    draft_combine_stats.to_excel(writer, index=False, sheet_name='draft_combine_stats')\n",
    "    print('2')\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a') as writer:\n",
    "    draft_history.to_excel(writer, index=False, sheet_name='draft_history')\n",
    "    print('3')\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a') as writer:\n",
    "    game_info.to_excel(writer, index=False, sheet_name='game_info')\n",
    "    print('4')\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a') as writer:\n",
    "    game.to_excel(writer, index=False, sheet_name='game')\n",
    "    print('5')\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a') as writer:\n",
    "    inactive_players.to_excel(writer, index=False, sheet_name='inactive_players')\n",
    "    print('6')\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a') as writer:\n",
    "    line_score.to_excel(writer, index=False, sheet_name='line_score')\n",
    "    print('7')\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a') as writer:\n",
    "    other_stats.to_excel(writer, index=False, sheet_name='other_stats')\n",
    "    print('8')\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a') as writer:\n",
    "    play_by_play.to_excel(writer, index=False, sheet_name='play_by_play')\n",
    "    print('9')\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a') as writer:\n",
    "    player.to_excel(writer, index=False, sheet_name='player')\n",
    "    print('10')\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a') as writer:\n",
    "    team_details.to_excel(writer, index=False, sheet_name='team_details')\n",
    "    print('11')\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a') as writer:\n",
    "    team.to_excel(writer, index=False, sheet_name='team')\n",
    "    print('12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_player_info: (113, 28)\n",
      "draft_combine_stats: (233, 41)\n",
      "draft_history: (112, 14)\n",
      "game_info: (27457, 4)\n",
      "game: (30426, 55)\n",
      "inactive_players: (11072, 7)\n",
      "line_score: (27457, 43)\n",
      "other_stats: (25165, 26)\n",
      "play_by_play: (726115, 33)\n",
      "player: (179, 3)\n",
      "team_details: (25, 11)\n",
      "team: (30, 7)\n"
     ]
    }
   ],
   "source": [
    "for table_name in tables:\n",
    "    print(f'{table_name}: {globals()[table_name].shape}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

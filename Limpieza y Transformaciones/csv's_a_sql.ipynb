{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es necesario descomprimir los dataset en '/Dataset Comprimido. Los path estan definidos para una descompresion sin alterar\n",
    "# nombres de carpetas ni de archivos\n",
    "\n",
    "tables = [\"f_common_player_info\", \"f_draft_combine_stats\", \"f_draft_history\", \"f_game_info\", \"f_game\", \"f_inactive_players\",\n",
    "          \"f_line_score\", \"f_other_stats\", \"f_play_by_play\", \"f_player\", \"f_team_details\", \"f_team\"]\n",
    "\n",
    "# Cargar cada archivo CSV en un DataFrame con el nombre del elemento en `tables`\n",
    "for table_name in tables:\n",
    "    globals()[table_name[2:]] = pd.read_csv(f\"Dataset Comprimido/Filtrados/csv/{table_name}.csv\")\n",
    "\n",
    "tables = [\"common_player_info\", \"draft_combine_stats\", \"draft_history\", \"game_info\", \"game\", \"inactive_players\",\n",
    "          \"line_score\", \"other_stats\", \"play_by_play\", \"player\", \"team_details\", \"team\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar columnas para el formateo\n",
    "columnas_string = ['player_id', 'player_name', 'school', 'country', 'last_affiliation', 'jersey', 'position', \n",
    "'team_id', 'team_name', 'team_abbreviation', 'team_code', 'team_city', 'playercode',\n",
    "'position', 'draft_type', 'organization', 'organization_type', 'game_id', 'team_id_home',\n",
    "'team_abbreviation_home', 'team_name_home', 'matchup_home', 'team_id_away',\n",
    "'team_abbreviation_away', 'team_name_away', 'matchup_away', 'season_type', 'team_city_name_home',\n",
    "'team_nickname_home', 'team_city_name_away', 'team_nickname_away', 'league_id', 'eventnum',\n",
    "'eventmsgtype', 'eventmsgactiontype', 'homedescription', 'visitordescription', 'score',\n",
    "'person1type', 'player1_id', 'player1_name', 'player1_team_id', 'player1_team_city', \n",
    "'player1_team_nickname', 'player1_team_abbreviation', 'player2_id', 'player2_name',\n",
    "'player2_team_id', 'player2_team_city', 'player2_team_nickname', 'player2_team_abbreviation',\n",
    "'player3_id', 'player3_name', 'player3_team_id', 'player3_team_city', 'player3_team_nickname',\n",
    "'player3_team_abbreviation', 'owner', 'generalmanager', 'headcoach', 'dleagueaffiliation', 'team_state',\n",
    "'season_exp', 'from_year', 'to_year', 'draft_year', 'round_pick', 'draft_number', 'season', 'round_number',\n",
    "'overall_pick', 'season_id', 'arena','yearfounded','year_founded']\n",
    "columnas_bool = ['rosterstatus', 'games_played_current_season_flag', 'dleague_flag', 'nba_flag',\n",
    "'games_played_flag', 'greatest_75_flag', 'player_profile_flag', 'wl_home', 'video_available_home',\n",
    "'wl_away', 'video_available_away', 'video_available_flag', 'is_active']\n",
    "columnas_date = ['birthdate', 'game_date']\n",
    "columnas_timestring = ['game_time', 'wctimestring', 'pctimestring']\n",
    "columnas_pulgadas = ['height', 'height_wo_shoes', 'height_w_shoes', 'wingspan', 'standing_reach', 'hand_length',\n",
    "'hand_width', 'standing_vertical_leap', 'max_vertical_leap']\n",
    "columnas_libras = ['weight']\n",
    "columnas_float3 = ['body_fat_pct', 'fg_pct_home', 'fg3_pct_home', 'ft_pct_home', 'fg_pct_away', 'fg3_pct_away', 'ft_pct_away']\n",
    "columnas_tiempo = ['lane_agility_time', 'modified_lane_agility_time', 'three_quarter_sprint']\n",
    "columnas_int = ['bench_press', 'attendance', 'fgm_home',\n",
    "'fga_home', 'fg3m_home', 'fg3a_home', 'ftm_home', 'fta_home', 'oreb_home', 'dreb_home',\n",
    "'reb_home', 'ast_home', 'stl_home', 'blk_home', 'tov_home', 'pts_home', 'plus_minus_home',\n",
    "'fgm_away', 'fga_away', 'fg3m_away', 'fg3a_away', 'ftm_away', 'fta_away', 'oreb_away',\n",
    "'dreb_away', 'reb_away', 'ast_away', 'stl_away', 'blk_away', 'tov_away', 'pf_away', 'pts_away',\n",
    "'plus_minus_away', 'game_sequence', 'pts_qtr1_home', 'pts_qtr2_home', 'pts_qtr3_home',\n",
    "'pts_qtr4_home', 'pts_ot1_home', 'pts_ot2_home', 'pts_ot3_home', 'pts_ot4_home', 'pts_ot5_home',\n",
    "'pts_ot6_home', 'pts_ot7_home', 'pts_ot8_home', 'pts_ot9_home', 'pts_ot10_home', 'pts_home',\n",
    "'pts_qtr1_away', 'pts_qtr2_away', 'pts_qtr3_away', 'pts_qtr4_away', 'pts_ot1_away',\n",
    "'pts_ot2_away', 'pts_ot3_away', 'pts_ot4_away', 'pts_ot5_away', 'pts_ot6_away', 'pts_ot7_away',\n",
    "'pts_ot8_away', 'pts_ot9_away', 'pts_ot10_away', 'pts_away', 'pts_paint_home', 'pts_2nd_chance_home',\n",
    "'pts_fb_home', 'largest_lead_home', 'lead_changes', 'times_tied', 'team_turnovers_home',\n",
    "'total_turnovers_home', 'team_rebounds_home', 'pts_off_to_home', 'pts_paint_away',\n",
    "'pts_2nd_chance_away', 'pts_fb_away', 'largest_lead_away', 'team_turnovers_away',\n",
    "'total_turnovers_away', 'team_rebounds_away', 'pts_off_to_away', 'period', 'scoremargin',\n",
    "'arenacapacity']\n",
    "columnas_fracciones = ['spot_fifteen_corner_left', 'spot_fifteen_break_left', 'spot_fifteen_top_key',\n",
    "'spot_fifteen_break_right', 'spot_fifteen_corner_right', 'spot_college_corner_left',\n",
    "'spot_college_break_left', 'spot_college_top_key', 'spot_college_break_right',\n",
    "'spot_college_corner_right', 'spot_nba_corner_left', 'spot_nba_break_left',\n",
    "'spot_nba_top_key', 'spot_nba_break_right', 'spot_nba_corner_right',\n",
    "'off_drib_fifteen_break_left', 'off_drib_fifteen_top_key', 'off_drib_fifteen_break_right',\n",
    "'off_drib_college_break_left', 'off_drib_college_top_key', 'off_drib_college_break_right',\n",
    "'on_move_fifteen', 'on_move_college']\n",
    "columnas_ratios = ['team_wins_losses_home', 'team_wins_losses_away']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicacion de formatos correspondientes\n",
    "# Recorrer cada DataFrame en la lista tables\n",
    "for df in tables:\n",
    "    \n",
    "    # Convertir columnas a string\n",
    "    for col in globals()[df].columns.intersection(columnas_string + columnas_bool + columnas_timestring):\n",
    "        globals()[df][col] = globals()[df][col].astype(str)\n",
    "    \n",
    "    # Convertir columnas a datetime\n",
    "    for col in globals()[df].columns.intersection(columnas_date):\n",
    "        globals()[df][col] = pd.to_datetime(globals()[df][col])  # 'coerce' convierte valores inválidos a NaT\n",
    "    \n",
    "    ''' # Aplicar formato para columnas en pulgadas\n",
    "    for col in globals()[df].columns.intersection(columnas_pulgadas):\n",
    "        globals()[df][col] = globals()[df][col].astype(float).map(lambda x: f\"{x:.2f} in\")\n",
    "    \n",
    "    # Aplicar formato para columnas en libras\n",
    "    for col in globals()[df].columns.intersection(columnas_libras):\n",
    "        globals()[df][col] = globals()[df][col].astype(float).map(lambda x: f\"{x:.2f} lbs\")'''\n",
    "    \n",
    "    # Aplicar formato para columnas float con 3 decimales\n",
    "    for col in globals()[df].columns.intersection(columnas_float3 + columnas_pulgadas + columnas_libras + columnas_tiempo):\n",
    "        globals()[df][col] = globals()[df][col].astype(float).round(3)\n",
    "    \n",
    "    '''# Aplicar formato para columnas de tiempo en segundos\n",
    "    for col in globals()[df].columns.intersection(columnas_tiempo):\n",
    "        globals()[df][col] = globals()[df][col].astype(float).map(lambda x: f\"{x:.3f} segs\")'''\n",
    "    \n",
    "    # Convertir columnas a enteros\n",
    "    for col in globals()[df].columns.intersection(columnas_int):\n",
    "        globals()[df][col] = globals()[df][col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexión a SQL Server con autenticación de Windows\n",
    "server = 'DESKTOP-XXXXXXX\\SQLEXPRESS'\n",
    "database = 'Nombre de BD creada previamente'\n",
    "params = urllib.parse.quote_plus(\n",
    "    f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "    f\"SERVER={server};\"\n",
    "    f\"DATABASE={database};\"\n",
    "    \"Trusted_Connection=yes;\" # Solo funciona para autentificacion de Windows, de otra forma hay que establecer UID y PWD\n",
    ")\n",
    "\n",
    "# Crear el motor de conexión\n",
    "engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3: Itera sobre cada hoja y carga como una tabla\n",
    "for table_name in tables:\n",
    "    try:\n",
    "        # Cargar el DataFrame en SQL Server usando el nombre de la hoja como el nombre de la tabla\n",
    "        globals()[table_name].to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "        print(f\"Datos del dataframe '{table_name}' cargados exitosamente en la tabla '{table_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error al cargar los datos de la hoja '{table_name}':\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
